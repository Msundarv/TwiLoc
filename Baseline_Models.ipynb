{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOnGmAePvBGK"
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer, TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "RSED6JRO7BEH",
    "outputId": "f18c3b47-7588-499c-a087-1f4d62bc0798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (218147, 2)\n",
      "Dev shape: (74079, 2)\n",
      "Test shape: (74382, 3)\n",
      "Tweet Test shape: (74382, 2)\n",
      "User Test shape: (1858, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load Training, Dev and Test Data\n",
    "\n",
    "def loadData(filepath):\n",
    "  data = pd.read_csv(filepath)\n",
    "  # Currently working on region level predictor\n",
    "  data.drop(['lat','long','state'],axis=1,inplace=True)\n",
    "  # Filter and remove anomaly data\n",
    "  data = data[data.region != 'MX']  # Remove 'Mexico' records - Due to Reverse geocoding\n",
    "  data = data[data.region != 'CA']  # Remove 'Canada' records - Due to Reverse geocoding\n",
    "  data.dropna(inplace=True)\n",
    "  data.reset_index(drop=True,inplace=True)\n",
    "  return data\n",
    "\n",
    "# train file and dev file has columns tweet, lat, long, state, region\n",
    "# test file has columns uid (userid), tweet, lat, long, state, region\n",
    "train = loadData(\"Path to train .csv file\")\n",
    "dev = loadData(\"Path to dev .csv file\")\n",
    "test = loadData(\"Path to test .csv file\")\n",
    "tweet_test = test.drop('uid', axis=1)  # Tweet level test\n",
    "user_test = test.drop('tweet', axis=1).drop_duplicates()  # User level test\n",
    "\n",
    "# print(train.head(5))\n",
    "# print(train.iloc[0])\n",
    "# print(train.region.unique())\n",
    "# train.info()\n",
    "print(\"Train shape: \"+ str(train.shape))\n",
    "print(\"Dev shape: \"+ str(dev.shape))\n",
    "print(\"Test shape: \"+ str(test.shape))\n",
    "print(\"Tweet Test shape: \"+ str(tweet_test.shape))\n",
    "print(\"User Test shape: \"+ str(user_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Ody5PVriu5Lt",
    "outputId": "df34edb6-9578-4ce3-f8c5-9d9309b3693d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (218147, 2)\n",
      "Dev shape: (74079, 2)\n",
      "Test shape: (74382, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Tweet cleaning\n",
    "tt = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "pat1 = r'@[A-Za-z0-9_]+'  # To remove '@' mentions\n",
    "pat2 = r'https?://[^ ]+'  # To remove web links starting with http\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'  # To remove web links starting without http\n",
    "'''negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')'''\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    stripped = re.sub(combined_pat, '', text)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    # neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    # letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # Will tokenize and join together to remove unneccessary white spaces\n",
    "    # words = [x for x  in wpt.tokenize(letters_only) if len(x) > 1]\n",
    "    words = [x for x  in tt.tokenize(lower_case) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "  \n",
    "# print(tweet_cleaner(\" www.msundarv.com don't First batting also dhik dhik, chasing also dhik dhik! Finger nails, toe nails, no bias! üò∑ #Yellove #WhistlePodu #CSKvRR ü¶Åüíõ\"))\n",
    "\n",
    "train.tweet = train.tweet.apply(tweet_cleaner)\n",
    "# print(train.head(5))\n",
    "# print(train.iloc[0])\n",
    "dev.tweet = dev.tweet.apply(tweet_cleaner)\n",
    "tweet_test.tweet = tweet_test.tweet.apply(tweet_cleaner)\n",
    "\n",
    "print(\"Train shape: \"+ str(train.shape))\n",
    "print(\"Dev shape: \"+ str(dev.shape))\n",
    "print(\"Test shape: \"+ str(tweet_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "rcFan4t81BB9",
    "outputId": "8da093d2-d9b3-48cf-84ea-ec8533f388cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape: (218147, 5000)\n",
      "X_Dev Shape: (74079, 5000)\n",
      "X_Test Shape: (74382, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorization\n",
    "\n",
    "tweet_vectorizer = TfidfVectorizer(max_features = 5000,ngram_range = (1,3),stop_words='english')\n",
    "\n",
    "X_train = tweet_vectorizer.fit_transform(train.tweet)\n",
    "X_dev = tweet_vectorizer.transform(dev.tweet)\n",
    "X_test = tweet_vectorizer.transform(tweet_test.tweet)\n",
    "\n",
    "print(\"X_Train Shape: \"+str(X_train.shape))\n",
    "print(\"X_Dev Shape: \"+str(X_dev.shape))\n",
    "print(\"X_Test Shape: \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "rnhgZLCYP_CX",
    "outputId": "0e72a02f-033b-4afc-a17d-8bc50be5fd4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Train Accuracy: 49.00\n",
      "NB Dev Accuracy: 46.45\n",
      "NB Test Accuracy: 45.09\n"
     ]
    }
   ],
   "source": [
    "# Baseline - NB Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, train.region)\n",
    "\n",
    "nb_train_score = nb_classifier.score(X_train, train.region)\n",
    "nb_dev_score = nb_classifier.score(X_dev, dev.region)\n",
    "nb_test_score = nb_classifier.score(X_test, test.region)\n",
    "\n",
    "# Tweet level Accuracy\n",
    "print(\"NB Train Accuracy: {:.2f}\".format(nb_train_score*100))\n",
    "print(\"NB Dev Accuracy: {:.2f}\".format(nb_dev_score*100))\n",
    "print(\"NB Test Accuracy: {:.2f}\".format(nb_test_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "s-bledy7miPe",
    "outputId": "11e9407b-46be-4540-b39b-e7032c1702ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Train Accuracy: 49.71\n",
      "LR Dev Accuracy: 46.14\n",
      "LR Test Accuracy: 44.82\n"
     ]
    }
   ],
   "source": [
    "# Baseline - LR Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, train.region)\n",
    "\n",
    "lr_train_score = lr_classifier.score(X_train, train.region)\n",
    "lr_dev_score = lr_classifier.score(X_dev, dev.region)\n",
    "lr_test_score = lr_classifier.score(X_test, test.region)\n",
    "\n",
    "# Tweet level Accuracy\n",
    "print(\"LR Train Accuracy: {:.2f}\".format(lr_train_score*100))\n",
    "print(\"LR Dev Accuracy: {:.2f}\".format(lr_dev_score*100))\n",
    "print(\"LR Test Accuracy: {:.2f}\".format(lr_test_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "bByYoQcC5WGY",
    "outputId": "a5bcb861-3ec7-4664-9594-483222427221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy: 47.78\n",
      "SVM Dev Accuracy: 44.95\n",
      "SVM Test Accuracy: 43.50\n"
     ]
    }
   ],
   "source": [
    "# Baseline - SVM Classifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# svm_classifier = svm.SVC(kernel='linear', verbose = 1)\n",
    "svm_classifier = SGDClassifier(max_iter=1000, tol=1e-3, shuffle = True)\n",
    "svm_classifier.fit(X_train, train.region)\n",
    "\n",
    "svm_train_score = svm_classifier.score(X_train, train.region)\n",
    "svm_dev_score = svm_classifier.score(X_dev, dev.region)\n",
    "svm_test_score = svm_classifier.score(X_test, test.region)\n",
    "\n",
    "# Tweet level Accuracy\n",
    "print(\"SVM Train Accuracy: {:.2f}\".format(svm_train_score*100))\n",
    "print(\"SVM Dev Accuracy: {:.2f}\".format(svm_dev_score*100))\n",
    "print(\"SVM Test Accuracy: {:.2f}\".format(svm_test_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o9sdqglV2YbH",
    "outputId": "11c727f6-6801-43d7-c8ce-43a866b71a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 51.88\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation - User level Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict region for each tweet using a trained model\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "# print(y_pred.shape)\n",
    "\n",
    "# Predict a region for each user\n",
    "test['ypred'] = y_pred\n",
    "user_pred = test.drop(['tweet','region'],axis=1)\n",
    "pred = user_pred.groupby(['uid'])['ypred'].agg(lambda x:x.value_counts().index[0])\n",
    "# print(pred.head(10))\n",
    "\n",
    "# Compare predicted values with ground truth \n",
    "true = user_test.sort_values(by=['uid'])\n",
    "# print(true.head(10))\n",
    "\n",
    "final_acc = accuracy_score(true['region'], pred)\n",
    "print(\"Final Accuracy: {:.2f}\".format(final_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PR1oiNrk4MJZ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline_Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
